{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0bed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPP-LNR-047\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce1bff",
   "metadata": {},
   "source": [
    "# Imports/Setpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# username = os.environ.get('USER')\n",
    "# scratch_base = f\"/scratch/midway3/{username}/fea_project\"\n",
    "# custom_lib_path = os.path.join(scratch_base, \"my_custom_libs\")\n",
    "# py_version = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "# site_packages = os.path.join(custom_lib_path, \"lib\", py_version, \"site-packages\")\n",
    "\n",
    "# # Clean up old installation\n",
    "# if os.path.exists(custom_lib_path):\n",
    "#     print(f\"Removing old libraries...\")\n",
    "#     shutil.rmtree(custom_lib_path)\n",
    "\n",
    "# install_cmd = (\n",
    "#     f\"pip install --target='{site_packages}' \"\n",
    "#     \"--upgrade \"\n",
    "#     \"--no-cache-dir \"\n",
    "#     \"'numpy<2.0' \"\n",
    "#     \"'pandas' \"\n",
    "#     \"'bottleneck' \"\n",
    "#     \"'numexpr' \"\n",
    "#     \"'torch' \"\n",
    "#     \"'torchvision' \"\n",
    "#     \"'accelerate>=0.31.0' \"\n",
    "#     \"'tensorflow' \"\n",
    "#     \"'tf-keras' \"\n",
    "#     \"'transformers' \"\n",
    "#     \"'sentence-transformers' \"\n",
    "#     \"'datasets' \"\n",
    "#     \"'botocore' \"\n",
    "#     \"'aiobotocore' \"\n",
    "#     \"'s3fs' \"\n",
    "#     \"'openpyxl' \"\n",
    "#     \"'sentencepiece' \"\n",
    "#     \"'plotly' \"\n",
    "#     \"'scikit-learn' \"\n",
    "#     \"'papermill' \"\n",
    "#     \"'scrapbook' \"\n",
    "#     \"'openai' \"\n",
    "#     \"'pydantic' \"\n",
    "#     \"'tqdm' \"\n",
    "# )\n",
    "\n",
    "# print(\"Installing with NumPy <2.0...\")\n",
    "# exit_code = os.system(install_cmd)\n",
    "\n",
    "# if exit_code == 0:\n",
    "#     print(\"\\nSUCCESS: Complete stack installed.\")\n",
    "# else:\n",
    "#     print(f\"\\nERROR: Installation failed with code {exit_code}\")\n",
    "\n",
    "# print(\"\\n##### RESTART KERNEL NOW #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13787109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is looking here first: /scratch/midway3/None/fea_project\\my_custom_libs\\lib\\python3.13\\site-packages\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mPYTHONUSERBASE\u001b[39m\u001b[33m'\u001b[39m] = custom_lib_path\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# --- 3. NOW IMPORT LIBRARIES ---\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Only import AFTER sys.path is updated\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m \n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\datasets\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m4.5.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Column, Dataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\datasets\\arrow_dataset.py:59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\__init__.py:58\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     60\u001b[39m     ArrowDtype,\n\u001b[32m     61\u001b[39m     Int8Dtype,\n\u001b[32m     62\u001b[39m     Int16Dtype,\n\u001b[32m     63\u001b[39m     Int32Dtype,\n\u001b[32m     64\u001b[39m     Int64Dtype,\n\u001b[32m     65\u001b[39m     UInt8Dtype,\n\u001b[32m     66\u001b[39m     UInt16Dtype,\n\u001b[32m     67\u001b[39m     UInt32Dtype,\n\u001b[32m     68\u001b[39m     UInt64Dtype,\n\u001b[32m     69\u001b[39m     Float32Dtype,\n\u001b[32m     70\u001b[39m     Float64Dtype,\n\u001b[32m     71\u001b[39m     CategoricalDtype,\n\u001b[32m     72\u001b[39m     PeriodDtype,\n\u001b[32m     73\u001b[39m     IntervalDtype,\n\u001b[32m     74\u001b[39m     DatetimeTZDtype,\n\u001b[32m     75\u001b[39m     StringDtype,\n\u001b[32m     76\u001b[39m     BooleanDtype,\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     78\u001b[39m     NA,\n\u001b[32m     79\u001b[39m     isna,\n\u001b[32m     80\u001b[39m     isnull,\n\u001b[32m     81\u001b[39m     notna,\n\u001b[32m     82\u001b[39m     notnull,\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     84\u001b[39m     Index,\n\u001b[32m     85\u001b[39m     CategoricalIndex,\n\u001b[32m     86\u001b[39m     RangeIndex,\n\u001b[32m     87\u001b[39m     MultiIndex,\n\u001b[32m     88\u001b[39m     IntervalIndex,\n\u001b[32m     89\u001b[39m     TimedeltaIndex,\n\u001b[32m     90\u001b[39m     DatetimeIndex,\n\u001b[32m     91\u001b[39m     PeriodIndex,\n\u001b[32m     92\u001b[39m     IndexSlice,\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     94\u001b[39m     NaT,\n\u001b[32m     95\u001b[39m     Period,\n\u001b[32m     96\u001b[39m     period_range,\n\u001b[32m     97\u001b[39m     Timedelta,\n\u001b[32m     98\u001b[39m     timedelta_range,\n\u001b[32m     99\u001b[39m     Timestamp,\n\u001b[32m    100\u001b[39m     date_range,\n\u001b[32m    101\u001b[39m     bdate_range,\n\u001b[32m    102\u001b[39m     Interval,\n\u001b[32m    103\u001b[39m     interval_range,\n\u001b[32m    104\u001b[39m     DateOffset,\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    106\u001b[39m     to_numeric,\n\u001b[32m    107\u001b[39m     to_datetime,\n\u001b[32m    108\u001b[39m     to_timedelta,\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    110\u001b[39m     Flags,\n\u001b[32m    111\u001b[39m     Grouper,\n\u001b[32m    112\u001b[39m     factorize,\n\u001b[32m    113\u001b[39m     unique,\n\u001b[32m    114\u001b[39m     NamedAgg,\n\u001b[32m    115\u001b[39m     array,\n\u001b[32m    116\u001b[39m     Categorical,\n\u001b[32m    117\u001b[39m     set_eng_float_format,\n\u001b[32m    118\u001b[39m     Series,\n\u001b[32m    119\u001b[39m     DataFrame,\n\u001b[32m    120\u001b[39m )\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\api.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array  \u001b[38;5;66;03m# noqa: ICN001\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     Grouper,\n\u001b[32m     48\u001b[39m     NamedAgg,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     51\u001b[39m     CategoricalIndex,\n\u001b[32m     52\u001b[39m     DatetimeIndex,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     TimedeltaIndex,\n\u001b[32m     59\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     61\u001b[39m     bdate_range,\n\u001b[32m     62\u001b[39m     date_range,\n\u001b[32m     63\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\groupby\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataFrameGroupBy,\n\u001b[32m      3\u001b[39m     NamedAgg,\n\u001b[32m      4\u001b[39m     SeriesGroupBy,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:64\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     GroupByApply,\n\u001b[32m     59\u001b[39m     maybe_mangle_lambdas,\n\u001b[32m     60\u001b[39m     reconstruct_func,\n\u001b[32m     61\u001b[39m     validate_func_kwargs,\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcom\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     67\u001b[39m     GroupBy,\n\u001b[32m     68\u001b[39m     GroupByPlot,\n\u001b[32m     69\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\frame.py:154\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    150\u001b[39m     ensure_wrapped_if_datetimelike,\n\u001b[32m    151\u001b[39m     sanitize_array,\n\u001b[32m    152\u001b[39m     sanitize_masked_array,\n\u001b[32m    153\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NDFrame\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_key_length\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    157\u001b[39m     DatetimeIndex,\n\u001b[32m    158\u001b[39m     Index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    162\u001b[39m     ensure_index_from_sequences,\n\u001b[32m    163\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\generic.py:177\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_docs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _shared_docs\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msorting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_indexer_indexer\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwindow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    178\u001b[39m     Expanding,\n\u001b[32m    179\u001b[39m     ExponentialMovingWindow,\n\u001b[32m    180\u001b[39m     Rolling,\n\u001b[32m    181\u001b[39m     Window,\n\u001b[32m    182\u001b[39m )\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    185\u001b[39m     DataFrameFormatter,\n\u001b[32m    186\u001b[39m     DataFrameRenderer,\n\u001b[32m    187\u001b[39m )\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprinting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pprint_thing\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\window\\__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwindow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mewm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     ExponentialMovingWindow,\n\u001b[32m      3\u001b[39m     ExponentialMovingWindowGroupby,\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwindow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpanding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     Expanding,\n\u001b[32m      7\u001b[39m     ExpandingGroupby,\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwindow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrolling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     Rolling,\n\u001b[32m     11\u001b[39m     RollingGroupby,\n\u001b[32m     12\u001b[39m     Window,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExpanding\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExpandingGroupby\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWindow\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1556\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1530\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1629\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:152\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "### Installs all the packages in the install library (my_custom_libs) ##\n",
    "\n",
    "# --- 1. SETUP PATHS FIRST (you are going to need to change to whatever your path to the instal library is in) ---\n",
    "username = os.environ.get('USER')\n",
    "scratch_base = f\"/scratch/midway3/{username}/fea_project\"\n",
    "custom_lib_path = os.path.join(scratch_base, \"my_custom_libs\")\n",
    "hf_cache_path = os.path.join(scratch_base, \"hf_cache\")\n",
    "\n",
    "py_version = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "site_packages = os.path.join(custom_lib_path, \"lib\", py_version, \"site-packages\")\n",
    "sys.path.insert(0, site_packages)\n",
    "\n",
    "# FORCE custom path to the FRONT of the list\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.insert(0, site_packages)\n",
    "\n",
    "print(f\"Python is looking here first: {sys.path[0]}\")\n",
    "\n",
    "# --- 2. ENV VARIABLES ---\n",
    "os.environ['HF_HOME'] = hf_cache_path\n",
    "os.environ['TRANSFORMERS_CACHE'] = hf_cache_path\n",
    "os.environ['PYTHONUSERBASE'] = custom_lib_path\n",
    "\n",
    "# --- 3. NOW IMPORT LIBRARIES ---\n",
    "# Only import AFTER sys.path is updated\n",
    "import datasets \n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- 4. VERIFY PATHS ---\n",
    "print(f\"Datasets is loaded from: {os.path.dirname(datasets.__file__)}\")\n",
    "\n",
    "if \"software\" in os.path.dirname(datasets.__file__):\n",
    "    print(\"FAILURE: Still loading system datasets.\")\n",
    "else:\n",
    "    print(\"SUCCESS: All libraries isolated in scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec22fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added current directory to sys.path: c:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\CODE\\free_entailment_algorithm\\fea_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "    print(f\"Added current directory to sys.path: {current_dir}\")\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import free_entailments_algorithm_utils as fea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc0f9e",
   "metadata": {},
   "source": [
    "# Global Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8706c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to False if running the real thing.\n",
    "\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb06e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "importlib.reload(fea)\n",
    "df_p = pd.read_excel(r\"C:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\DATA\\round2_extra_speeches\\Jan2026\\final\\ClauseLevel_df_p.xlsx\")\n",
    "df_sc = pd.read_excel(r\"C:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\DATA\\round2_extra_speeches\\Jan2026\\final\\ClauseLevel_df_sc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd352ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating premise-premise pairs ===\n",
      "  Dataset size: 29635 (9564 books, 20071 speeches)\n",
      "  Max possible valid pairs: 237,689,310\n",
      "  Seen-index tracking: 0 BB + 0 BS already consumed (45,730,266 BB + 191,959,044 BS remaining)\n",
      "  Sampling 3,835,253 pairs from 237,689,310 possible...\n",
      "    BB: sampled 737,884 pairs (seen 0, avail 45,730,266)\n",
      "    BS: sampled 3,097,369 pairs (seen 0, avail 191,959,044)\n",
      "  Generated 3,835,253 unique pairs\n",
      "\n",
      "=== Generating conclusion-conclusion pairs ===\n",
      "  Dataset size: 9000 (2511 books, 6489 speeches)\n",
      "  Max possible valid pairs: 19,445,184\n",
      "  Seen-index tracking: 0 BB + 0 BS already consumed (3,151,305 BB + 16,293,879 BS remaining)\n",
      "  Sampling 1,164,747 pairs from 19,445,184 possible...\n",
      "    BB: sampled 188,760 pairs (seen 0, avail 3,151,305)\n",
      "    BS: sampled 975,987 pairs (seen 0, avail 16,293,879)\n",
      "  Generated 1,164,747 unique pairs\n",
      "\n",
      "=== SUMMARY ===\n",
      "Premise-premise pairs: 3,835,253\n",
      "Conclusion-conclusion pairs: 1,164,747\n",
      "Total valid pairs: 5,000,000\n",
      "Columns: ['id1', 'id2']\n",
      "Filtered out 23 already-labeled pairs (kept 4,999,977 of 5,000,000)\n",
      "Generated 4,999,977 unlabeled pairs (after excluding already-labeled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9241"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "## All clauses. Of the form: argument_id\tsentence_id\tsentence\n",
    "\n",
    "df_clause = pd.concat([df_p,df_sc]).drop_duplicates(subset='sentence_id')\n",
    "\n",
    "# Generate initial unlabeled pairs (production mode only).\n",
    "# We generate up to 50M pairs (BB + BS), excluding any already-labeled pairs.\n",
    "# These are randomly sampled from the ~450M valid candidate space.\n",
    "# seen_indices_dir persists consumed pair indices across rounds so\n",
    "# subsequent rounds never re-sample pairs from earlier rounds.\n",
    "\n",
    "if not test:\n",
    "    df_pairs = fea.generate_valid_pairs(\n",
    "        df_p,\n",
    "        df_sc,\n",
    "        'sentence_id',\n",
    "        'sentence',\n",
    "        max_pairs=5_000_000,\n",
    "        exclude_labeled_csv=\"labeled_pairs/llm_labeled_pairs.csv\",\n",
    "        seen_indices_dir=\"seen_pair_indices\",\n",
    "    )\n",
    "    print(f\"Generated {len(df_pairs):,} unlabeled pairs (after excluding already-labeled)\")\n",
    "\n",
    "# Free source DataFrames â€” all data preserved in df_clause and df_pairs\n",
    "del df_p, df_sc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4e388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10989e09bbc14474aa231ebf6128b421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Creating Embedding Cache\n",
      "Model: C:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\CODE\\free_entailment_algorithm\\fea_project\\fine_tuned_bi_model\n",
      "Total unique texts: 37474\n",
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d783be16984b7f83e28f8e4f6c4dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded existing embedding cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(embedding_cache_finetuned)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Create cache from all unique clauses\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     embedding_cache_finetuned = \u001b[43mfea\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_embedding_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_clause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43maesteva\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDropbox\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mCulture\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43m3_data_processing\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43m10_Argumentation\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mEntailment\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mCODE\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mfree_entailment_algorithm\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mfea_project\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mfine_tuned_bi_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Save to disk for future runs\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cache_path, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\CODE\\free_entailment_algorithm\\fea_project\\free_entailments_algorithm_utils.py:988\u001b[39m, in \u001b[36mcreate_embedding_cache\u001b[39m\u001b[34m(df_texts, id_col, text_col, model_name, batch_size, show_progress_bar)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDevice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    987\u001b[39m \u001b[38;5;66;03m# Encode all texts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m embeddings = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_unique\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Return numpy arrays for efficiency\u001b[39;49;00m\n\u001b[32m    993\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# Create dictionary mapping id -> embedding\u001b[39;00m\n\u001b[32m    996\u001b[39m embedding_cache = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    997\u001b[39m     df_unique[id_col].astype(\u001b[38;5;28mstr\u001b[39m),  \u001b[38;5;66;03m# Convert IDs to string for consistency\u001b[39;00m\n\u001b[32m    998\u001b[39m     embeddings\n\u001b[32m    999\u001b[39m ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\utils\\_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# pyrefly: ignore [bad-context-manager]\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:262\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    264\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\generic.py:1001\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    999\u001b[39m             outputs = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m         outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1003\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1004\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1005\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1006\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:696\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    679\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    680\u001b[39m     input_ids=input_ids,\n\u001b[32m    681\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m attention_mask, encoder_attention_mask = \u001b[38;5;28mself\u001b[39m._create_attention_masks(\n\u001b[32m    688\u001b[39m     attention_mask=attention_mask,\n\u001b[32m    689\u001b[39m     encoder_attention_mask=encoder_attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    693\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    694\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m sequence_output = encoder_outputs.last_hidden_state\n\u001b[32m    708\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:452\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    442\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    450\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor] | BaseModelOutputWithPastAndCrossAttentions:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer):\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m         hidden_states = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    456\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPastAndCrossAttentions(\n\u001b[32m    463\u001b[39m         last_hidden_state=hidden_states,\n\u001b[32m    464\u001b[39m         past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    465\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         logger.warning_once(message)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    413\u001b[39m     cross_attention_output, _ = \u001b[38;5;28mself\u001b[39m.crossattention(\n\u001b[32m    414\u001b[39m         self_attention_output,\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# attention_mask\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    419\u001b[39m         **kwargs,\n\u001b[32m    420\u001b[39m     )\n\u001b[32m    421\u001b[39m     attention_output = cross_attention_output\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\pytorch_utils.py:201\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:429\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:348\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # Creates Embedding Cache (If not already created) from df_clause:\n",
    "# importlib.reload(fea)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# cache_path = \"embedding_cache_finetuned2.pkl\"\n",
    "\n",
    "# if os.path.exists(cache_path):\n",
    "#     with open(cache_path, 'rb') as f:\n",
    "#         embedding_cache_finetuned = pickle.load(f)\n",
    "#     print(f\"Loaded existing embedding cache: {len(embedding_cache_finetuned)} embeddings\")\n",
    "# else:\n",
    "#     # Create cache from all unique clauses\n",
    "#     embedding_cache_finetuned = fea.create_embedding_cache(\n",
    "#     df_texts=df_clause,\n",
    "#     id_col='sentence_id',\n",
    "#     text_col='sentence',\n",
    "#     model_name=\"C:\\\\Users\\\\aesteva\\\\Dropbox\\\\Culture\\\\3_data_processing\\\\10_Argumentation\\\\Entailment\\\\CODE\\\\free_entailment_algorithm\\\\fea_project\\\\fine_tuned_bi_model\",\n",
    "#     batch_size=128,\n",
    "#     show_progress_bar=True\n",
    "# )\n",
    "#     # Save to disk for future runs\n",
    "#     with open(cache_path, 'wb') as f:\n",
    "#         pickle.dump(embedding_cache_finetuned, f)\n",
    "#     print(f\"Saved embedding cache to {cache_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4affa1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set difference: 4,999,977 - 1,998 = 4,999,977 rows\n",
      "Unlabeled pairs after removing labeled: 4,999,977\n",
      "âœ“ Freed df_pairs (only unlabeled_pairs kept in memory)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "input_file = \"labeled_pairs/Results_DS_BtoS_iteration_0.csv\"\n",
    "df_input = pd.read_csv(input_file)\n",
    "\n",
    "if test:\n",
    "    importlib.reload(fea)\n",
    "    df_input = pd.read_csv(input_file)\n",
    "    \n",
    "    input_file, remaining_llm_calls = fea.two_random_subsamples(\n",
    "        df = df_input,\n",
    "        frac1 = 0.8,\n",
    "        frac2 = 0.2,\n",
    "        random_state = 42\n",
    "    )\n",
    "else:\n",
    "    remaining_llm_calls = None\n",
    "    # Use Results_DS_BtoS_iteration_0 as labeled input,\n",
    "    # and subtract already-labeled pairs from the 20M unlabeled pool\n",
    "    df_entailed_pairs = df_input.rename(columns={'sentence_id_1': 'id1', 'sentence_id_2': 'id2'})\n",
    "    unlabeled_pairs = fea.setminus(df_pairs, df_entailed_pairs, [\"id1\", \"id2\"])\n",
    "    print(f\"Unlabeled pairs after removing labeled: {len(unlabeled_pairs):,}\")\n",
    "\n",
    "    # Free the 75M-row df_pairs â€” unlabeled_pairs is the only copy we need.\n",
    "    # This saves ~3 GB of RAM in the FEA_Loop kernel, which persists while\n",
    "    # FEA_Pipeline and FreeEntailmentAlgorithm run in their own sub-processes.\n",
    "    del df_pairs, df_entailed_pairs\n",
    "    gc.collect()\n",
    "    print(\"âœ“ Freed df_pairs (only unlabeled_pairs kept in memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812698fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding cache: 38635 embeddings\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"embedding_cache_finetuned.pkl\", 'rb') as f:\n",
    "    embedding_cache_finetuned = pickle.load(f)\n",
    "print(f\"Loaded embedding cache: {len(embedding_cache_finetuned)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f463c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 2          # hard cap (set high â€“ budget is the real limiter)\n",
    "iteration_stats = []\n",
    "\n",
    "sent_frac = 0.5\n",
    "budget = 5.00\n",
    "\n",
    "# ---- Budget controls ----\n",
    "# The loop stops automatically once cumulative LLM spend reaches budget_dollars.\n",
    "# Set to None for unlimited (loop runs until num_iterations).\n",
    "budget_dollars = 5.00       \n",
    "cost_per_1k_pairs = 2.0       # ~$2 per 1,000 pairs (DeepSeek R1)\n",
    "\n",
    "# DeepSeek API key for production LLM calls\n",
    "api_key = os.environ.get(\"DEEPSEEK_API_KEY\", \"sk-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a607ca8",
   "metadata": {},
   "source": [
    "# FEA Loop using Papermill\n",
    "\n",
    "This notebook uses papermill to iteratively run the FEA_Pipeline notebook, feeding the output of each iteration as input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52a5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"fea_iterations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "start_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5393ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FEA Loop with 2 iterations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting FEA Loop with {num_iterations} iterations\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b4bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATING INITIAL DATA STATE\n",
      "============================================================\n",
      "Initial labeled pairs: 1998\n",
      "Initial unlabeled pairs: 4999977\n",
      "Total: 5001975\n",
      "âœ“ Cleaned up old loop data directory\n",
      "Starting with 1998 already labeled pairs\n",
      "Unlabeled pool: 4999977\n",
      "Total pairs: 5001975\n",
      "Budget: $5.00  ($2.00 / 1k pairs)\n",
      "\n",
      "============================================================\n",
      "ITERATION 0/2\n",
      "============================================================\n",
      "Status: Labeled=1998, Unlabeled=4999977, Total=5001975\n",
      "Cost so far: $0.00  ($5.00 remaining)\n",
      "Executing FEA_Pipeline.ipynb with input: labeled_pairs/Results_DS_BtoS_iteration_0.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfdf8eefae8487a80e11f0abb73ec9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Retrieved df_to_llm from scrapbook\n",
      "  Shape: (1000, 7)\n",
      "  Columns: ['sentence_id_2', 'sentence_id_1', 'sentence_text_2', 'argument_id_2', 'sentence_text_1', 'argument_id_1', 'score']\n",
      "âœ“ Saved df_to_llm to fea_iterations\\loop_data/df_to_llm_iter_0.csv\n",
      "\n",
      "============================================================\n",
      "EXECUTING LLM EVALUATOR (forward direction)\n",
      "============================================================\n",
      "Sending 1000 pairs to LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1387db49af38404888399b00bdaf8f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Forward LLM evaluation complete\n",
      "âœ“ LLM labeled pairs updated: 2997 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "ONE-WAY RESULTS PROCESSING\n",
      "============================================================\n",
      "Total input pairs: 1000\n",
      "Resolved rows: 1938 (YES=0, NO=1938)\n",
      "  â†³ Inferred reverse NO (money saved): 969\n",
      "Need reverse LLM call: 20\n",
      "============================================================\n",
      "\n",
      "âœ“ LLM labeled pairs updated: 3966 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "âœ“ Recorded 969 inferred reverse-NO pairs in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "SENDING 20 REVERSE PAIRS TO LLM\n",
      "============================================================\n",
      "Model: deepseek-reasoner\n",
      "Input: labeled_pairs\\reverse_iter_0_input.csv\n",
      "Output: labeled_pairs\\reverse_iter_0_output.csv\n",
      "Loading data from labeled_pairs\\reverse_iter_0_input.csv...\n",
      "Loading data from ArgLevel_ClauseIds_df.xlsx...\n",
      "Loaded 20 sentence pairs\n",
      "Using model: deepseek-reasoner\n",
      "Using prompt type: test_prompt_tot_json2\n",
      "Running batch evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] content length: 1282, reasoning_content length: 8275\n",
      "[DEBUG] content preview: {\n",
      "  \"sentence_id_1\": \"B0285007p\",\n",
      "  \"sentence_id_2\": \"B0021002p\",\n",
      "  \"answers\": \"YES, NO, NO\",\n",
      "  \"reasoning\": \"1. YES: If legitimate authority stems from the will of the people, then when individuals consent to form a community, they must establish a mechanism to express that will, and majority rule \n",
      "[DEBUG] reasoning preview: First, I need to determine if Statement 1 entails Statement 2. Statement 1 is: \"Legitimate authority stems from the will of the people.\" Statement 2 is: \"When individuals consent to form a community, they collectively create a single body politic, which operates based on the will of the majority.\"\n",
      "\n",
      "\n",
      "Saved results to labeled_pairs\\reverse_iter_0_output.csv\n",
      "âœ“ Reverse LLM evaluation complete\n",
      "âœ“ LLM labeled pairs updated: 3985 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "REVERSE RESULTS SUMMARY\n",
      "============================================================\n",
      "Total reverse pairs resolved: 40\n",
      "  Bidirectional YES: 6\n",
      "  Bidirectional NO:  34\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "BIDIRECTIONAL PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total resolved pairs: 1978\n",
      "  YES (bidirectional): 6\n",
      "  NO:                  1972\n",
      "Saved to: labeled_pairs/Results_DS_BtoS_iteration_1.csv\n",
      "============================================================\n",
      "\n",
      "âœ“ Merged 1998 previous + 1978 new = 3976 total\n",
      "âœ“ Processed 1000 NEW pairs\n",
      "  â†’ Labeled input: 1998\n",
      "  â†’ Unlabeled available: 4999977\n",
      "  â†’ Iteration cost: $2.00  (cumulative: $2.00)\n",
      "\n",
      "============================================================\n",
      "ITERATION 1/2\n",
      "============================================================\n",
      "Status: Labeled=2998, Unlabeled=4998977, Total=5001975\n",
      "Cost so far: $2.00  ($3.00 remaining)\n",
      "Executing FEA_Pipeline.ipynb with input: labeled_pairs/Results_DS_BtoS_iteration_1.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5779659ea104957ade813fc298a8702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Retrieved df_to_llm from scrapbook\n",
      "  Shape: (1000, 7)\n",
      "  Columns: ['sentence_id_2', 'sentence_id_1', 'sentence_text_2', 'argument_id_2', 'sentence_text_1', 'argument_id_1', 'score']\n",
      "âœ“ Saved df_to_llm to fea_iterations\\loop_data/df_to_llm_iter_1.csv\n",
      "\n",
      "============================================================\n",
      "EXECUTING LLM EVALUATOR (forward direction)\n",
      "============================================================\n",
      "Sending 1000 pairs to LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8a30b79d274150a7404a644296dc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Forward LLM evaluation complete\n",
      "âœ“ LLM labeled pairs updated: 4985 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "ONE-WAY RESULTS PROCESSING\n",
      "============================================================\n",
      "Total input pairs: 1000\n",
      "Resolved rows: 1920 (YES=0, NO=1920)\n",
      "  â†³ Inferred reverse NO (money saved): 960\n",
      "Need reverse LLM call: 37\n",
      "============================================================\n",
      "\n",
      "âœ“ LLM labeled pairs updated: 5945 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "âœ“ Recorded 960 inferred reverse-NO pairs in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "SENDING 37 REVERSE PAIRS TO LLM\n",
      "============================================================\n",
      "Model: deepseek-reasoner\n",
      "Input: labeled_pairs\\reverse_iter_1_input.csv\n",
      "Output: labeled_pairs\\reverse_iter_1_output.csv\n",
      "Loading data from labeled_pairs\\reverse_iter_1_input.csv...\n",
      "Loading data from ArgLevel_ClauseIds_df.xlsx...\n",
      "Loaded 37 sentence pairs\n",
      "Using model: deepseek-reasoner\n",
      "Using prompt type: test_prompt_tot_json2\n",
      "Running batch evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:00<00:00, 48.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] content length: 1547, reasoning_content length: 7069\n",
      "[DEBUG] content preview: {\n",
      "  \"sentence_id_1\": \"S0024115003p\",\n",
      "  \"sentence_id_2\": \"B0536006p\",\n",
      "  \"answers\": \"NO, YES, NO\",\n",
      "  \"reasoning\": \"1. NO: Statement 1 is a broad principle about political integrity, while Statement 2 is a specific claim about resisting unlawful authority. There is no logical necessity that the former \n",
      "[DEBUG] reasoning preview: We are given two arguments and two statements derived from them. Statement 1: \"Safeguarding the integrity of the political system is important\" comes from Argument 1. Statement 2: \"This principle holds true regardless of the level of authority, as even subordinate magistrates can be opposed if they \n",
      "Saved results to labeled_pairs\\reverse_iter_1_output.csv\n",
      "âœ“ Reverse LLM evaluation complete\n",
      "âœ“ LLM labeled pairs updated: 5982 total in labeled_pairs/llm_labeled_pairs.csv\n",
      "\n",
      "============================================================\n",
      "REVERSE RESULTS SUMMARY\n",
      "============================================================\n",
      "Total reverse pairs resolved: 74\n",
      "  Bidirectional YES: 24\n",
      "  Bidirectional NO:  50\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "BIDIRECTIONAL PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total resolved pairs: 1994\n",
      "  YES (bidirectional): 24\n",
      "  NO:                  1970\n",
      "Saved to: labeled_pairs/Results_DS_BtoS_iteration_2.csv\n",
      "============================================================\n",
      "\n",
      "âœ“ Merged 3976 previous + 1994 new = 5970 total\n",
      "âœ“ Processed 1000 NEW pairs\n",
      "  â†’ Labeled input: 2998\n",
      "  â†’ Unlabeled available: 4998977\n",
      "  â†’ Iteration cost: $2.00  (cumulative: $4.00)\n",
      "\n",
      "============================================================\n",
      "ITERATION 2/2\n",
      "============================================================\n",
      "Status: Labeled=3998, Unlabeled=4997977, Total=5001975\n",
      "Cost so far: $4.00  ($1.00 remaining)\n",
      "Executing FEA_Pipeline.ipynb with input: labeled_pairs/Results_DS_BtoS_iteration_2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f1730ffafb4868a87d9361f25eb427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m importlib.reload(fea)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m iteration_stats = \u001b[43mfea\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_fea_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_clause\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_clause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_cache_finetuned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msent_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43msent_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremaining_llm_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremaining_llm_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43munlabeled_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlabeled_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munlabeled_pairs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeepseek_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbudget_dollars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbudget_dollars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcost_per_1k_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcost_per_1k_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\CODE\\free_entailment_algorithm\\fea_project\\free_entailments_algorithm_utils.py:4635\u001b[39m, in \u001b[36mrun_fea_loop\u001b[39m\u001b[34m(test, input_file, df_clause, embedding_cache, num_iterations, start_iteration, output_dir, sent_frac, budget, remaining_llm_calls, unlabeled_pairs, deepseek_api_key, budget_dollars, cost_per_1k_pairs)\u001b[39m\n\u001b[32m   4622\u001b[39m parameters = {\n\u001b[32m   4623\u001b[39m     \u001b[33m'\u001b[39m\u001b[33miteration_number\u001b[39m\u001b[33m'\u001b[39m: iteration,\n\u001b[32m   4624\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_csv_path\u001b[39m\u001b[33m'\u001b[39m: input_csv_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4631\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbudget\u001b[39m\u001b[33m'\u001b[39m: budget,\n\u001b[32m   4632\u001b[39m }\n\u001b[32m   4634\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting FEA_Pipeline.ipynb with input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_csv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4635\u001b[39m \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4636\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFEA_Pipeline.ipynb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4637\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_notebook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4639\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4641\u001b[39m output_csv = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfea_iterations/llm_batch_iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\execute.py:116\u001b[39m, in \u001b[36mexecute_notebook\u001b[39m\u001b[34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Execute the Notebook in `cwd` if it is set\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m chdir(cwd):\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     nb = \u001b[43mpapermill_engines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_notebook_with_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_save_on_cell_execute\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstdout_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstderr_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[32m    131\u001b[39m raise_for_execution_errors(nb, output_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\engines.py:48\u001b[39m, in \u001b[36mPapermillEngines.execute_notebook_with_engine\u001b[39m\u001b[34m(self, engine_name, nb, kernel_name, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_notebook_with_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine_name, nb, kernel_name, **kwargs):\n\u001b[32m     47\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fetch a named engine and execute the nb object against it.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\engines.py:370\u001b[39m, in \u001b[36mEngine.execute_notebook\u001b[39m\u001b[34m(cls, nb, kernel_name, output_path, progress_bar, log_output, autosave_cell_every, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m nb_man.notebook_start()\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_managed_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_man\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    372\u001b[39m     nb_man.cleanup_pbar()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\engines.py:442\u001b[39m, in \u001b[36mNBClientEngine.execute_managed_notebook\u001b[39m\u001b[34m(cls, nb_man, kernel_name, log_output, stdout_file, stderr_file, start_timeout, execution_timeout, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Nicely handle preprocessor arguments prioritizing values set by engine\u001b[39;00m\n\u001b[32m    432\u001b[39m final_kwargs = merge_kwargs(\n\u001b[32m    433\u001b[39m     safe_kwargs,\n\u001b[32m    434\u001b[39m     timeout=execution_timeout \u001b[38;5;28;01mif\u001b[39;00m execution_timeout \u001b[38;5;28;01melse\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     stderr_file=stderr_file,\n\u001b[32m    441\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPapermillNotebookClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_man\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinal_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\clientwrap.py:45\u001b[39m, in \u001b[36mPapermillNotebookClient.execute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.setup_kernel(**kwargs):\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting notebook with kernel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.kernel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpapermill_execute_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     info_msg = \u001b[38;5;28mself\u001b[39m.wait_for_reply(\u001b[38;5;28mself\u001b[39m.kc.kernel_info())\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m.nb.metadata[\u001b[33m'\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m'\u001b[39m] = info_msg[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\papermill\\clientwrap.py:72\u001b[39m, in \u001b[36mPapermillNotebookClient.papermill_execute_cells\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m.nb_man.cell_start(cell, index)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CellExecutionError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m.nb_man.cell_exception(\u001b[38;5;28mself\u001b[39m.nb.cells[index], cell_index=index, exception=ex)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\jupyter_core\\utils\\__init__.py:171\u001b[39m, in \u001b[36mrun_sync.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _runner_map:\n\u001b[32m    170\u001b[39m     _runner_map[name] = _TaskRunner()\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runner_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\jupyter_core\\utils\\__init__.py:128\u001b[39m, in \u001b[36m_TaskRunner.run\u001b[39m\u001b[34m(self, coro)\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[38;5;28mself\u001b[39m.__runner_thread.start()\n\u001b[32m    127\u001b[39m fut = asyncio.run_coroutine_threadsafe(coro, \u001b[38;5;28mself\u001b[39m.__io_loop)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mconcurrent\\futures\\_base.py:451\u001b[39m, in \u001b[36mresult\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mthreading.py:359\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(fea)\n",
    "\n",
    "iteration_stats = fea.run_fea_loop(\n",
    "    test=test,\n",
    "    input_file=input_file,\n",
    "    df_clause=df_clause,\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    num_iterations=num_iterations,\n",
    "    start_iteration=start_iteration,\n",
    "    output_dir=output_dir,\n",
    "    sent_frac=sent_frac,\n",
    "    budget=budget,\n",
    "    remaining_llm_calls=remaining_llm_calls,\n",
    "    unlabeled_pairs=unlabeled_pairs if 'unlabeled_pairs' in dir() else None,\n",
    "    deepseek_api_key=api_key,\n",
    "    budget_dollars=budget_dollars,\n",
    "    cost_per_1k_pairs=cost_per_1k_pairs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ecc7483-2853-472e-ba44-4c50a17ff30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration Statistics:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pairs_selected'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stats_df = \u001b[43mfea\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_iteration_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Dropbox\\Culture\\3_data_processing\\10_Argumentation\\Entailment\\CODE\\free_entailment_algorithm\\fea_project\\free_entailments_algorithm_utils.py:4841\u001b[39m, in \u001b[36msave_iteration_stats\u001b[39m\u001b[34m(iteration_stats, output_dir, cost_per_pair)\u001b[39m\n\u001b[32m   4838\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIteration Statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4839\u001b[39m \u001b[38;5;28mprint\u001b[39m(stats_df)\n\u001b[32m-> \u001b[39m\u001b[32m4841\u001b[39m total_pairs_sent = \u001b[43mstats_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpairs_selected\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sum()\n\u001b[32m   4843\u001b[39m \u001b[38;5;66;03m# Use tracked cost if available, else fall back to simple estimate\u001b[39;00m\n\u001b[32m   4844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcumulative_cost\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stats_df.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stats_df) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:525\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    523\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    526\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'pairs_selected'"
     ]
    }
   ],
   "source": [
    "stats_df = fea.save_iteration_stats(iteration_stats, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc41b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final output: verdict=YES pairs only, AB/BA duplicates collapsed to a single AB row.\n",
    "# The last iteration's output_file contains all accumulated labeled pairs.\n",
    "_final_csv = iteration_stats[-1]['output_file']\n",
    "_df_all = pd.read_csv(_final_csv)\n",
    "\n",
    "# Standardize column names\n",
    "_id1_col = 'sentence_id_1' if 'sentence_id_1' in _df_all.columns else 'id1'\n",
    "_id2_col = 'sentence_id_2' if 'sentence_id_2' in _df_all.columns else 'id2'\n",
    "\n",
    "# Keep only YES verdicts\n",
    "_df_yes = _df_all[_df_all['verdict'] == 'YES'].copy()\n",
    "\n",
    "# Normalize pairs: always store (min, max) so AB and BA map to the same row\n",
    "_a = _df_yes[_id1_col].astype(str)\n",
    "_b = _df_yes[_id2_col].astype(str)\n",
    "_df_yes['id1'] = np.where(_a <= _b, _a, _b)\n",
    "_df_yes['id2'] = np.where(_a <= _b, _b, _a)\n",
    "_df_yes['Verdict'] = 'YES'\n",
    "\n",
    "df_out = _df_yes[['id1', 'id2', 'Verdict']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_out.to_excel('df_out.xlsx', index=False)\n",
    "print(f\"df_out: {len(df_out)} unique entailed pairs (from {len(_df_yes)} YES rows, {len(_df_all)} total)\")\n",
    "df_out.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41bec4fd-a9ce-43ce-935b-38d81fa52d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_out = pd.read_csv(r\"labeled_pairs\\\\Results_DS_BtoS_iteration_2.csv\")\n",
    "df_out = df_out[df_out['verdict'] == 'YES'].copy()\n",
    "_id1_col = 'sentence_id_1' if 'sentence_id_1' in df_out.columns else 'id1'\n",
    "_id2_col = 'sentence_id_2' if 'sentence_id_2' in df_out.columns else 'id2'\n",
    "_a = df_out[_id1_col].astype(str)\n",
    "_b = df_out[_id2_col].astype(str)\n",
    "df_out['id1'] = np.where(_a <= _b, _a, _b)\n",
    "df_out['id2'] = np.where(_a <= _b, _b, _a)\n",
    "df_out['verdict'] = 'YES'\n",
    "\n",
    "df_out = df_out[['id1', 'id2', 'verdict']].drop_duplicates().reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200c5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head()\n",
    "df_out.to_excel('df_out.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
