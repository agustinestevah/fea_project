{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0bed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midway3-0277.rcc.local\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce1bff",
   "metadata": {},
   "source": [
    "# Imports/Setpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# username = os.environ.get('USER')\n",
    "# scratch_base = f\"/scratch/midway3/{username}/fea_project\"\n",
    "# custom_lib_path = os.path.join(scratch_base, \"my_custom_libs\")\n",
    "# py_version = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "# site_packages = os.path.join(custom_lib_path, \"lib\", py_version, \"site-packages\")\n",
    "\n",
    "# # Clean up old installation\n",
    "# if os.path.exists(custom_lib_path):\n",
    "#     print(f\"Removing old libraries...\")\n",
    "#     shutil.rmtree(custom_lib_path)\n",
    "\n",
    "# install_cmd = (\n",
    "#     f\"pip install --target='{site_packages}' \"\n",
    "#     \"--upgrade \"\n",
    "#     \"--no-cache-dir \"\n",
    "#     \"'numpy<2.0' \"\n",
    "#     \"'pandas' \"\n",
    "#     \"'bottleneck' \"\n",
    "#     \"'numexpr' \"\n",
    "#     \"'torch' \"\n",
    "#     \"'torchvision' \"\n",
    "#     \"'accelerate>=0.31.0' \"\n",
    "#     \"'tensorflow' \"\n",
    "#     \"'tf-keras' \"\n",
    "#     \"'transformers' \"\n",
    "#     \"'sentence-transformers' \"\n",
    "#     \"'datasets' \"\n",
    "#     \"'botocore' \"\n",
    "#     \"'aiobotocore' \"\n",
    "#     \"'s3fs' \"\n",
    "#     \"'openpyxl' \"\n",
    "#     \"'sentencepiece' \"\n",
    "#     \"'plotly' \"\n",
    "#     \"'scikit-learn' \"\n",
    "#     \"'papermill' \"\n",
    "#     \"'scrapbook' \"\n",
    "#     \"'openai' \"\n",
    "#     \"'pydantic' \"\n",
    "#     \"'tqdm' \"\n",
    "# )\n",
    "\n",
    "# print(\"Installing with NumPy <2.0...\")\n",
    "# exit_code = os.system(install_cmd)\n",
    "\n",
    "# if exit_code == 0:\n",
    "#     print(\"\\nSUCCESS: Complete stack installed.\")\n",
    "# else:\n",
    "#     print(f\"\\nERROR: Installation failed with code {exit_code}\")\n",
    "\n",
    "# print(\"\\n##### RESTART KERNEL NOW #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13787109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is looking here first: /scratch/midway3/aesteva/fea_project/my_custom_libs/lib/python3.11/site-packages\n",
      "Datasets is loaded from: /scratch/midway3/aesteva/fea_project/my_custom_libs/lib/python3.11/site-packages/datasets\n",
      "SUCCESS: All libraries isolated in scratch.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "### Installs all the packages in the install library (my_custom_libs) ##\n",
    "\n",
    "# --- 1. SETUP PATHS FIRST (you are going to need to change to whatever your path to the instal library is in) ---\n",
    "username = os.environ.get('USER')\n",
    "scratch_base = f\"/scratch/midway3/{username}/fea_project\"\n",
    "custom_lib_path = os.path.join(scratch_base, \"my_custom_libs\")\n",
    "hf_cache_path = os.path.join(scratch_base, \"hf_cache\")\n",
    "\n",
    "py_version = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "site_packages = os.path.join(custom_lib_path, \"lib\", py_version, \"site-packages\")\n",
    "sys.path.insert(0, site_packages)\n",
    "\n",
    "# FORCE custom path to the FRONT of the list\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.insert(0, site_packages)\n",
    "\n",
    "print(f\"Python is looking here first: {sys.path[0]}\")\n",
    "\n",
    "# --- 2. ENV VARIABLES ---\n",
    "os.environ['HF_HOME'] = hf_cache_path\n",
    "os.environ['TRANSFORMERS_CACHE'] = hf_cache_path\n",
    "os.environ['PYTHONUSERBASE'] = custom_lib_path\n",
    "\n",
    "# --- 3. NOW IMPORT LIBRARIES ---\n",
    "# Only import AFTER sys.path is updated\n",
    "import datasets \n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- 4. VERIFY PATHS ---\n",
    "print(f\"Datasets is loaded from: {os.path.dirname(datasets.__file__)}\")\n",
    "\n",
    "if \"software\" in os.path.dirname(datasets.__file__):\n",
    "    print(\"FAILURE: Still loading system datasets.\")\n",
    "else:\n",
    "    print(\"SUCCESS: All libraries isolated in scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec22fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import free_entailments_algorithm_utils as fea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc0f9e",
   "metadata": {},
   "source": [
    "# Global Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8706c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to False if running the real thing.\n",
    "\n",
    "test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a317584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(fea)\n",
    "\n",
    "#List of all sentences/sentence ids being used\n",
    "df_p = pd.read_excel(\"ClauseLevel_df_p.xlsx\")\n",
    "df_sc = pd.read_excel(\"ClauseLevel_df_sc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All clauses. Of the form: argument_id\tsentence_id\tsentence\n",
    "\n",
    "df_clause = pd.concat([df_p,df_sc]).drop_duplicates(subset='sentence_id')\n",
    "\n",
    "# We do the 0.5 billion pairs in batches:\n",
    "# We compare books-books, books-speech, never speech-speech. \n",
    "# We also compare premise-premise, conclusion-conclusion, never premise-conclusion\n",
    "\n",
    "if not test:\n",
    "    df_pairs = fea.generate_valid_pairs(\n",
    "            df_p,\n",
    "            df_sc,\n",
    "            'sentence_id',\n",
    "            'sentence',\n",
    "            max_pairs = 25,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates Embedding Cache (If not already created) from df_clause:\n",
    "# import pickle\n",
    "\n",
    "# cache_path = \"embedding_cache_finetuned.pkl\"\n",
    "\n",
    "# if os.path.exists(cache_path):\n",
    "#     with open(cache_path, 'rb') as f:\n",
    "#         embedding_cache_finetuned = pickle.load(f)\n",
    "#     print(f\"Loaded existing embedding cache: {len(embedding_cache_finetuned)} embeddings\")\n",
    "# else:\n",
    "#     # Create cache from all unique clauses\n",
    "#     embedding_cache_finetuned = fea.create_embedding_cache(\n",
    "#         df_texts=df_clause,\n",
    "#         id_col='sentence_id',\n",
    "#         text_col='sentence',\n",
    "#         model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "#         batch_size=128,\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "#     # Save to disk for future runs\n",
    "#     with open(cache_path, 'wb') as f:\n",
    "#         pickle.dump(embedding_cache_finetuned, f)\n",
    "#     print(f\"Saved embedding cache to {cache_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4affa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"labeled_pairs/Results_DS_BtoS_iteration_0.csv\"\n",
    "df_input = pd.read_csv(input_file)\n",
    "\n",
    "if test:\n",
    "    importlib.reload(fea)\n",
    "    df_input = pd.read_csv(input_file)\n",
    "    \n",
    "    input_file, remaining_llm_calls = fea.two_random_subsamples(\n",
    "        df = df_input,\n",
    "        frac1 = 0.5,\n",
    "        frac2 = 0.5,\n",
    "        random_state = 42\n",
    "    )\n",
    "else:\n",
    "    remaining_llm_calls = None\n",
    "    df_entailed_pairs = df_input.rename(columns={'sentence_id_1': 'id1', 'sentence_id_2': 'id2'})\n",
    "    unlabeled_pairs = fea.setminus(df_pairs, df_entailed_pairs, [\"id1\", \"id2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812698fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding cache: 63909 embeddings\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"embedding_cache_finetuned.pkl\", 'rb') as f:\n",
    "    embedding_cache_finetuned = pickle.load(f)\n",
    "print(f\"Loaded embedding cache: {len(embedding_cache_finetuned)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f463c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 3\n",
    "total_cost = 0.0\n",
    "iteration_stats = []\n",
    "\n",
    "sent_frac = 0.5\n",
    "budget = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a607ca8",
   "metadata": {},
   "source": [
    "# FEA Loop using Papermill\n",
    "\n",
    "This notebook uses papermill to iteratively run the FEA_Pipeline notebook, feeding the output of each iteration as input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52a5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"fea_iterations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "start_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5393ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FEA Loop with 3 iterations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting FEA Loop with {num_iterations} iterations\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b4bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATING INITIAL DATA STATE\n",
      "============================================================\n",
      "Initial labeled pairs: 5000\n",
      "Initial unlabeled pairs: 5000\n",
      "Total: 10000\n",
      "✓ Cleaned up old loop data directory\n",
      "Starting with 5000 already labeled pairs\n",
      "Unlabeled pool: 5000\n",
      "Total pairs: 10000\n",
      "\n",
      "============================================================\n",
      "ITERATION 0/3\n",
      "============================================================\n",
      "Status: Labeled=5000, Unlabeled=5000, Total=10000\n",
      "Executing FEA_Pipeline.ipynb with input: fea_iterations/loop_data/input_iter_0.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68fe0194a544fed8279daadfe83da20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Output has 103 NEW pairs\n",
      "✓ Accumulated dataset now has 5103 total labeled pairs\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 10000\n",
      "Bidirectional entailment (YES): 1215 (12.2%)\n",
      "Not bidirectionally entailed (NO): 8785 (87.8%)\n",
      "======================================================================\n",
      "\n",
      "    Bidirectionally entailed: 44/103 (42.7%)\n",
      "  → Labeled input: 5000\n",
      "  → Unlabeled available: 5000\n",
      "\n",
      "============================================================\n",
      "ITERATION 1/3\n",
      "============================================================\n",
      "Status: Labeled=5103, Unlabeled=4897, Total=10000\n",
      "Executing FEA_Pipeline.ipynb with input: fea_iterations/loop_data/accumulated_labeled_iter_0.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433d8eb4a6e84ee8a33a9c9ded2820cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Output has 52 NEW pairs\n",
      "✓ Accumulated dataset now has 5155 total labeled pairs\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 10000\n",
      "Bidirectional entailment (YES): 1215 (12.2%)\n",
      "Not bidirectionally entailed (NO): 8785 (87.8%)\n",
      "======================================================================\n",
      "\n",
      "    Bidirectionally entailed: 13/52 (25.0%)\n",
      "  → Labeled input: 5103\n",
      "  → Unlabeled available: 4897\n",
      "\n",
      "============================================================\n",
      "ITERATION 2/3\n",
      "============================================================\n",
      "Status: Labeled=5155, Unlabeled=4845, Total=10000\n",
      "Executing FEA_Pipeline.ipynb with input: fea_iterations/loop_data/accumulated_labeled_iter_1.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd48feafb6654e239d0a4048a01577f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Output has 27 NEW pairs\n",
      "✓ Accumulated dataset now has 5182 total labeled pairs\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 10000\n",
      "Bidirectional entailment (YES): 1215 (12.2%)\n",
      "Not bidirectionally entailed (NO): 8785 (87.8%)\n",
      "======================================================================\n",
      "\n",
      "    Bidirectionally entailed: 12/27 (44.4%)\n",
      "  → Labeled input: 5155\n",
      "  → Unlabeled available: 4845\n",
      "\n",
      "============================================================\n",
      "ITERATION 3/3\n",
      "============================================================\n",
      "Status: Labeled=5182, Unlabeled=4818, Total=10000\n",
      "Executing FEA_Pipeline.ipynb with input: fea_iterations/loop_data/accumulated_labeled_iter_2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508f295e1632449a92bdedea69ad6932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/26 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Output has 15 NEW pairs\n",
      "✓ Accumulated dataset now has 5197 total labeled pairs\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 10000\n",
      "Bidirectional entailment (YES): 1215 (12.2%)\n",
      "Not bidirectionally entailed (NO): 8785 (87.8%)\n",
      "======================================================================\n",
      "\n",
      "    Bidirectionally entailed: 2/15 (13.3%)\n",
      "  → Labeled input: 5182\n",
      "  → Unlabeled available: 4818\n",
      "\n",
      "============================================================\n",
      "FEA Loop Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(fea)\n",
    "\n",
    "iteration_stats = fea.run_fea_loop(\n",
    "    test=test,\n",
    "    input_file=input_file,\n",
    "    df_clause=df_clause,\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    num_iterations=num_iterations,\n",
    "    start_iteration=start_iteration,\n",
    "    output_dir=output_dir,\n",
    "    sent_frac=sent_frac,\n",
    "    budget=budget,\n",
    "    remaining_llm_calls=remaining_llm_calls,\n",
    "    unlabeled_pairs=unlabeled_pairs if 'unlabeled_pairs' in dir() else None,\n",
    "    deepseek_api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecc7483-2853-472e-ba44-4c50a17ff30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration Statistics:\n",
      "   iteration  labeled_input  unlabeled_available  pairs_selected  \\\n",
      "0          0           5000                 5000             103   \n",
      "1          1           5103                 4897              52   \n",
      "2          2           5155                 4845              27   \n",
      "3          3           5182                 4818              15   \n",
      "\n",
      "   cumulative_labeled  unlabeled_remaining  \\\n",
      "0                5103                 4897   \n",
      "1                5155                 4845   \n",
      "2                5182                 4818   \n",
      "3                5197                 4803   \n",
      "\n",
      "                           output_file  entailment_ratio  \n",
      "0  fea_iterations/llm_batch_iter_0.csv          0.427184  \n",
      "1  fea_iterations/llm_batch_iter_1.csv          0.250000  \n",
      "2  fea_iterations/llm_batch_iter_2.csv          0.444444  \n",
      "3  fea_iterations/llm_batch_iter_3.csv          0.133333  \n",
      "\n",
      "============================================================\n",
      "COST SUMMARY\n",
      "============================================================\n",
      "Total pairs sent to LLM: 197\n",
      "Cost per pair: $0.001900\n",
      "Total cost: $0.3743\n",
      "============================================================\n",
      "\n",
      "✓ Saved iteration statistics to fea_iterations/iteration_stats.csv\n"
     ]
    }
   ],
   "source": [
    "stats_df = fea.save_iteration_stats(iteration_stats, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bec4fd-a9ce-43ce-935b-38d81fa52d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
