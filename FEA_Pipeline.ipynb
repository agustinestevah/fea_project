{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5201f8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscrapbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Ensure project root is on sys.path (required for papermill fresh kernels)\u001b[39;00m\n\u001b[32m     11\u001b[39m current_dir = os.getcwd()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     AutoConfig,\n\u001b[32m     23\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     24\u001b[39m     AutoTokenizer,\n\u001b[32m     25\u001b[39m     PretrainedConfig,\n\u001b[32m     26\u001b[39m     PreTrainedModel,\n\u001b[32m     27\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     28\u001b[39m     is_torch_npu_available,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2045\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2043\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module:\n\u001b[32m   2044\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2045\u001b[39m         module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2046\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2048\u001b[39m         \u001b[38;5;66;03m# V5: If trying to import a *TokenizerFast symbol, transparently fall back to the\u001b[39;00m\n\u001b[32m   2049\u001b[39m         \u001b[38;5;66;03m# non-Fast symbol from the same module when available. This lets us keep only one\u001b[39;00m\n\u001b[32m   2050\u001b[39m         \u001b[38;5;66;03m# backend tokenizer class while preserving legacy public names.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2237\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   2236\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2237\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2238\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mimportlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\models\\__init__.py:441\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m    440\u001b[39m _file = \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\u001b[34m__name__\u001b[39m, _file, \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m, module_spec=__spec__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2761\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2737\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2738\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2739\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2740\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2741\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2759\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2760\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2761\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2762\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2764\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2475\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2473\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m   2474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os.path.isdir(os.path.join(module_path, f)):\n\u001b[32m-> \u001b[39m\u001b[32m2475\u001b[39m         import_structure[f] = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2477\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n\u001b[32m   2478\u001b[39m         adjacent_modules.append(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aesteva\\Downloads\\python-3.13.12-embed-amd64\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2474\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2471\u001b[39m adjacent_modules = []\n\u001b[32m   2473\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m-> \u001b[39m\u001b[32m2474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2475\u001b[39m         import_structure[f] = create_import_structure_from_path(os.path.join(module_path, f))\n\u001b[32m   2477\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Ensure project root is on sys.path (required for papermill fresh kernels)\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "import free_entailments_algorithm_utils as fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e5bba9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "iteration_number = 1\n",
    "input_csv_path = \"labeled_pairs/Results_DS_BtoS_iteration_0.csv\"\n",
    "df_clause_path = None\n",
    "embedding_cache_path = None\n",
    "test = True\n",
    "remaining_llm_calls_path = None\n",
    "unlabeled_pairs_path = None\n",
    "sent_frac = 0.5\n",
    "budget = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095ee19-2788-4f9e-8045-317fc74c3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data = fea.load_pipeline_data(\n",
    "    df_clause_path=df_clause_path,\n",
    "    embedding_cache_path=embedding_cache_path,\n",
    "    test=test,\n",
    "    remaining_llm_calls_path=remaining_llm_calls_path,\n",
    "    unlabeled_pairs_path=unlabeled_pairs_path,\n",
    "    iteration_number=iteration_number,\n",
    ")\n",
    "\n",
    "df_clause = pipeline_data['df_clause']\n",
    "embedding_cache_finetuned = pipeline_data['embedding_cache']\n",
    "remaining_llm_calls = pipeline_data['remaining_llm_calls']\n",
    "unlabeled_pairs = pipeline_data['unlabeled_pairs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48afa33",
   "metadata": {},
   "source": [
    "# Task 1: Seting up dataframes and Running FEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost so far: $0.0000\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 2000\n",
      "Bidirectional entailment (YES): 241 (12.0%)\n",
      "Not bidirectionally entailed (NO): 1759 (87.9%)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "VERDICT SUMMARY\n",
      "======================================================================\n",
      "Total pairs: 8000\n",
      "Bidirectional entailment (YES): 974 (12.2%)\n",
      "Not bidirectionally entailed (NO): 7026 (87.8%)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_llm_original = pd.read_csv(input_csv_path)\n",
    "\n",
    "# If 'verdict' column already exists (e.g. from process_llm_results_bidirectional),\n",
    "# use it directly instead of recomputing via add_verdict (which only sees one-way\n",
    "# conclusions and would overwrite correct bidirectional verdicts).\n",
    "if 'verdict' in df_llm_original.columns and df_llm_original['verdict'].notna().any():\n",
    "    df_llm = df_llm_original\n",
    "    print(f\"Using existing 'verdict' column ({(df_llm['verdict']=='YES').sum()} YES, {(df_llm['verdict']=='NO').sum()} NO)\")\n",
    "else:\n",
    "    df_llm = fea.add_verdict(\n",
    "        df_llm_original,\n",
    "        id1_col='sentence_id_1',\n",
    "        id2_col='sentence_id_2',\n",
    "        conclusion_col='llm_conclusion_12',\n",
    "        positive_label='YES'\n",
    "    )\n",
    "\n",
    "if test:\n",
    "    df_llm_remaining = fea.add_verdict(\n",
    "        remaining_llm_calls,\n",
    "        id1_col='sentence_id_1',\n",
    "        id2_col='sentence_id_2',\n",
    "        conclusion_col='llm_conclusion_12',\n",
    "        positive_label='YES'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ec35c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0860002sc</td>\n",
       "      <td>S0010771002sc</td>\n",
       "      <td>The king's support must match his responsibili...</td>\n",
       "      <td>clear evidence of acting against the interests...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1170001sc</td>\n",
       "      <td>S0020225001sc</td>\n",
       "      <td>Active governance by the prince is essential f...</td>\n",
       "      <td>Maintaining respect for the monarchy is essential</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0454001p</td>\n",
       "      <td>S0004868005p</td>\n",
       "      <td>Agrarian laws can effectively prevent the rise...</td>\n",
       "      <td>This situation highlights the tension between ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0227001sc</td>\n",
       "      <td>S0000883002sc</td>\n",
       "      <td>Parliament should hold the power to correct le...</td>\n",
       "      <td>Parliament must uphold the rule of law</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0580002sc</td>\n",
       "      <td>S0023399001sc</td>\n",
       "      <td>The king's presence is essential for validatin...</td>\n",
       "      <td>Parliament must assert authority</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id1            id2  \\\n",
       "0  B0860002sc  S0010771002sc   \n",
       "1  B1170001sc  S0020225001sc   \n",
       "2   B0454001p   S0004868005p   \n",
       "3  B0227001sc  S0000883002sc   \n",
       "4  B0580002sc  S0023399001sc   \n",
       "\n",
       "                                               text1  \\\n",
       "0  The king's support must match his responsibili...   \n",
       "1  Active governance by the prince is essential f...   \n",
       "2  Agrarian laws can effectively prevent the rise...   \n",
       "3  Parliament should hold the power to correct le...   \n",
       "4  The king's presence is essential for validatin...   \n",
       "\n",
       "                                               text2 verdict  \n",
       "0  clear evidence of acting against the interests...      NO  \n",
       "1  Maintaining respect for the monarchy is essential      NO  \n",
       "2  This situation highlights the tension between ...      NO  \n",
       "3             Parliament must uphold the rule of law     YES  \n",
       "4                   Parliament must assert authority      NO  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = fea.merge_pairwise_texts(\n",
    "    df1 = df_clause,\n",
    "    df2 = df_llm,\n",
    "    df1_cols = ['sentence_id', 'sentence'],\n",
    "    df2_cols = ['sentence_id_1', 'sentence_id_2', 'verdict']\n",
    ")\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ad685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0859002p</td>\n",
       "      <td>S5393003p</td>\n",
       "      <td>The authority of a king is divinely ordained a...</td>\n",
       "      <td>The assertion that the king's power is derived...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0672011p</td>\n",
       "      <td>S15260001p</td>\n",
       "      <td>Ensuring the stability and governance of the s...</td>\n",
       "      <td>Establishing a stable government requires adhe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0589007p</td>\n",
       "      <td>S0000863004p</td>\n",
       "      <td>The rebellion was provoked by the subjects' at...</td>\n",
       "      <td>King Charles I believed that asserting his aut...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0382001p</td>\n",
       "      <td>S8507005p</td>\n",
       "      <td>The authority of a king is not absolute; it is...</td>\n",
       "      <td>The supremacy of royal authority in governance...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1114001sc</td>\n",
       "      <td>S0000941002sc</td>\n",
       "      <td>The connection between protection and obedienc...</td>\n",
       "      <td>to advocate for peace</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id1            id2  \\\n",
       "0   B0859002p      S5393003p   \n",
       "1   B0672011p     S15260001p   \n",
       "2   B0589007p   S0000863004p   \n",
       "3   B0382001p      S8507005p   \n",
       "4  B1114001sc  S0000941002sc   \n",
       "\n",
       "                                               text1  \\\n",
       "0  The authority of a king is divinely ordained a...   \n",
       "1  Ensuring the stability and governance of the s...   \n",
       "2  The rebellion was provoked by the subjects' at...   \n",
       "3  The authority of a king is not absolute; it is...   \n",
       "4  The connection between protection and obedienc...   \n",
       "\n",
       "                                               text2  verdict  \n",
       "0  The assertion that the king's power is derived...      NaN  \n",
       "1  Establishing a stable government requires adhe...      NaN  \n",
       "2  King Charles I believed that asserting his aut...      NaN  \n",
       "3  The supremacy of royal authority in governance...      NaN  \n",
       "4                              to advocate for peace      NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "if test:\n",
    "    df_predict = fea.merge_pairwise_texts(\n",
    "        df1 = df_clause,\n",
    "        df2 = df_llm_remaining,\n",
    "        df1_cols = ['sentence_id', 'sentence'],\n",
    "        df2_cols = ['sentence_id_1', 'sentence_id_2']\n",
    "    )\n",
    "else:\n",
    "    # At 20M+ pairs, we skip merge_pairwise_texts on the full pool\n",
    "    # (pairs were already validated at generation, text not needed until\n",
    "    #  the small df_final at the end). Just remove already-labeled pairs.\n",
    "    df_predict = fea.setminus(\n",
    "        df_big= unlabeled_pairs,\n",
    "        df_small= df_labeled,\n",
    "        id_cols = ['id1', 'id2']\n",
    "    )\n",
    "    df_predict['verdict'] = np.nan\n",
    "\n",
    "    # Free unlabeled_pairs immediately — it consumed ~3 GB and is no longer\n",
    "    # needed (df_predict is the working copy).  We will reload from pickle\n",
    "    # later when finalize_pipeline_iteration needs it.\n",
    "    del unlabeled_pairs\n",
    "    gc.collect()\n",
    "    print(\"✓ Freed unlabeled_pairs (will reload from pickle before finalize)\")\n",
    "\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d636c53",
   "metadata": {},
   "source": [
    "## Embedding All Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Patched transformers.utils.hub\n",
      " - Patched transformers.tokenization_utils_base\n",
      "\n",
      "SUCCESS: The 404 error is now blocked.\n"
     ]
    }
   ],
   "source": [
    "## Patches an error later on with kwargs\n",
    "import transformers.utils.hub\n",
    "import transformers.tokenization_utils_base\n",
    "\n",
    "def _safe_list_templates(*args, **kwargs):\n",
    "    return []\n",
    "\n",
    "transformers.utils.hub.list_repo_templates = _safe_list_templates\n",
    "print(\" - Patched transformers.utils.hub\")\n",
    "\n",
    "# The library had already imported the broken function here, so we must update it.\n",
    "transformers.tokenization_utils_base.list_repo_templates = _safe_list_templates\n",
    "print(\" - Patched transformers.tokenization_utils_base\")\n",
    "\n",
    "print(\"\\nSUCCESS: The 404 error is now blocked.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2383f79",
   "metadata": {},
   "source": [
    "## Test and Validation Subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ffa5f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0227001sc</td>\n",
       "      <td>S0000883002sc</td>\n",
       "      <td>Parliament should hold the power to correct le...</td>\n",
       "      <td>Parliament must uphold the rule of law</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B0134001sc</td>\n",
       "      <td>S0004953001sc</td>\n",
       "      <td>Governance derives its legitimacy from the peo...</td>\n",
       "      <td>Governance legitimacy should come from the wil...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B0794007p</td>\n",
       "      <td>S0000823011p</td>\n",
       "      <td>King Charles's actions demonstrate a tyrannica...</td>\n",
       "      <td>King Charles I's disregard for the people's vo...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B0161002p</td>\n",
       "      <td>S15310007p</td>\n",
       "      <td>Such actions threaten the liberties and well-b...</td>\n",
       "      <td>Such actions endanger the rights of individual...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B0252006p</td>\n",
       "      <td>S0000715007p</td>\n",
       "      <td>The authority of governing bodies, like Parlia...</td>\n",
       "      <td>Parliament serves as a check on the power of t...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id1            id2  \\\n",
       "3   B0227001sc  S0000883002sc   \n",
       "18  B0134001sc  S0004953001sc   \n",
       "20   B0794007p   S0000823011p   \n",
       "22   B0161002p     S15310007p   \n",
       "26   B0252006p   S0000715007p   \n",
       "\n",
       "                                                text1  \\\n",
       "3   Parliament should hold the power to correct le...   \n",
       "18  Governance derives its legitimacy from the peo...   \n",
       "20  King Charles's actions demonstrate a tyrannica...   \n",
       "22  Such actions threaten the liberties and well-b...   \n",
       "26  The authority of governing bodies, like Parlia...   \n",
       "\n",
       "                                                text2 verdict  \n",
       "3              Parliament must uphold the rule of law     YES  \n",
       "18  Governance legitimacy should come from the wil...     YES  \n",
       "20  King Charles I's disregard for the people's vo...     YES  \n",
       "22  Such actions endanger the rights of individual...     YES  \n",
       "26  Parliament serves as a check on the power of t...     YES  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only entailed pairs from sent\n",
    "df_obs_ent = df_labeled.loc[df_labeled['verdict'] == 'YES']\n",
    "df_obs_ent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da45922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Memory-efficient path for large candidate pools ---\n",
    "# Uses vectorised alpha + equiv_map lookups instead of storing\n",
    "# Python list objects in every row (saves ~8 GB at 75M rows).\n",
    "LARGE_THRESHOLD = 5_000_000\n",
    "\n",
    "if len(df_predict) > LARGE_THRESHOLD:\n",
    "    print(f\"Using memory-efficient path ({len(df_predict):,} candidate rows)\")\n",
    "    df_candidates, df_crossed, equiv_map = fea.prepare_candidates_efficient(\n",
    "        df_obs_ent=df_obs_ent,\n",
    "        df_predict=df_predict,\n",
    "        df_clause=df_clause,\n",
    "    )\n",
    "else:\n",
    "    # Original path (fine for small DataFrames)\n",
    "    df_candidates = fea.add_equivalents_from_pairs(\n",
    "        df3=df_obs_ent,\n",
    "        df4=df_predict,\n",
    "        df3_cols=[\"id1\", \"id2\"],\n",
    "        df4_cols=[\"id1\", \"id2\"],\n",
    "        new_cols=(\"equivalents1\", \"equivalents2\"),\n",
    "        include_self=False,\n",
    "    )\n",
    "    df_candidates = fea.add_alpha_weight_column(\n",
    "        df = df_candidates,\n",
    "        list_col1 = 'equivalents1',\n",
    "        list_col2 = 'equivalents2',\n",
    "        new_col = \"alpha\"\n",
    "    )\n",
    "    equiv_map = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cbc10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = fea.add_equivalents_from_pairs(\n",
    "    df3=df_obs_ent,\n",
    "    df4=df_labeled,\n",
    "    df3_cols=[\"id1\", \"id2\"],\n",
    "    df4_cols=[\"id1\", \"id2\"],\n",
    "    new_cols=(\"equivalents1\", \"equivalents2\"),\n",
    "    include_self=False,  # keep the ID itself in the list\n",
    ")\n",
    "\n",
    "df_labeled = fea.add_alpha_weight_column(\n",
    "    df = df_labeled,\n",
    "    list_col1 = 'equivalents1',\n",
    "    list_col2 = 'equivalents2',\n",
    "    new_col = \"alpha\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1178ec2",
   "metadata": {},
   "source": [
    "## Equivalence Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713f3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 1228 pairs (kept 710).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1015002sc</td>\n",
       "      <td>B1009004sc</td>\n",
       "      <td>A stable society enables individual flourishing</td>\n",
       "      <td>Foster societal cohesion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0312002p</td>\n",
       "      <td>B0659002p</td>\n",
       "      <td>The concept of a free monarchy fundamentally c...</td>\n",
       "      <td>The legitimacy of royal power is rooted in the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0781006p</td>\n",
       "      <td>B0223012p</td>\n",
       "      <td>The King's duty to uphold justice is emphasized</td>\n",
       "      <td>Limiting a King's authority to the consent of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0278001sc</td>\n",
       "      <td>B0795002sc</td>\n",
       "      <td>The King's power should be limited to promote ...</td>\n",
       "      <td>The King does not govern for the people's benefit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0190002p</td>\n",
       "      <td>B0223001p</td>\n",
       "      <td>The legitimacy of royal power is contingent up...</td>\n",
       "      <td>The authority of a King should indeed be limit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id1         id2                                              text1  \\\n",
       "0  B1015002sc  B1009004sc    A stable society enables individual flourishing   \n",
       "1   B0312002p   B0659002p  The concept of a free monarchy fundamentally c...   \n",
       "2   B0781006p   B0223012p    The King's duty to uphold justice is emphasized   \n",
       "3  B0278001sc  B0795002sc  The King's power should be limited to promote ...   \n",
       "4   B0190002p   B0223001p  The legitimacy of royal power is contingent up...   \n",
       "\n",
       "                                               text2  verdict  \n",
       "0                           Foster societal cohesion      NaN  \n",
       "1  The legitimacy of royal power is rooted in the...      NaN  \n",
       "2  Limiting a King's authority to the consent of ...      NaN  \n",
       "3  The King does not govern for the people's benefit      NaN  \n",
       "4  The authority of a King should indeed be limit...      NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only compute crossed pairs here if we used the original (small) path above.\n",
    "# The efficient path already produced df_crossed.\n",
    "if equiv_map is None:\n",
    "    df_crossed = fea.build_equiv_pair_candidates(\n",
    "        df = df_candidates,\n",
    "        id1_col = \"id1\",\n",
    "        id2_col = \"id2\",\n",
    "        equiv1_col = \"equivalents1\",\n",
    "        equiv2_col = \"equivalents2\",\n",
    "    )\n",
    "    df_crossed = fea.merge_pairwise_texts(\n",
    "        df1 = df_clause,\n",
    "        df2 = df_crossed,\n",
    "        df1_cols = ['sentence_id', 'sentence'],\n",
    "        df2_cols = ['id1', 'id2']\n",
    "    )\n",
    "\n",
    "df_crossed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d19e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 510 pairs (kept 456).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0227001sc</td>\n",
       "      <td>B0227001sc</td>\n",
       "      <td>Parliament should hold the power to correct le...</td>\n",
       "      <td>Parliament should hold the power to correct le...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0244002sc</td>\n",
       "      <td>B0311001sc</td>\n",
       "      <td>Parliaments in England can create laws indepen...</td>\n",
       "      <td>The king requires parliamentary approval to im...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0089006p</td>\n",
       "      <td>B0800005p</td>\n",
       "      <td>The rights and liberties of the people depend ...</td>\n",
       "      <td>The authority of a king or any governing body ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0134001sc</td>\n",
       "      <td>B0134001sc</td>\n",
       "      <td>Governance derives its legitimacy from the peo...</td>\n",
       "      <td>Governance derives its legitimacy from the peo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0794007p</td>\n",
       "      <td>B0794007p</td>\n",
       "      <td>King Charles's actions demonstrate a tyrannica...</td>\n",
       "      <td>King Charles's actions demonstrate a tyrannica...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id1         id2                                              text1  \\\n",
       "0  B0227001sc  B0227001sc  Parliament should hold the power to correct le...   \n",
       "1  B0244002sc  B0311001sc  Parliaments in England can create laws indepen...   \n",
       "2   B0089006p   B0800005p  The rights and liberties of the people depend ...   \n",
       "3  B0134001sc  B0134001sc  Governance derives its legitimacy from the peo...   \n",
       "4   B0794007p   B0794007p  King Charles's actions demonstrate a tyrannica...   \n",
       "\n",
       "                                               text2  verdict  \n",
       "0  Parliament should hold the power to correct le...      NaN  \n",
       "1  The king requires parliamentary approval to im...      NaN  \n",
       "2  The authority of a king or any governing body ...      NaN  \n",
       "3  Governance derives its legitimacy from the peo...      NaN  \n",
       "4  King Charles's actions demonstrate a tyrannica...      NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled_crossed = fea.build_equiv_pair_candidates(\n",
    "    df = df_labeled,\n",
    "    id1_col = \"id1\",\n",
    "    id2_col = \"id2\",\n",
    "    equiv1_col = \"equivalents1\",\n",
    "    equiv2_col = \"equivalents2\",\n",
    ")\n",
    "\n",
    "# Retrieve clause sentences\n",
    "df_labeled_crossed = fea.merge_pairwise_texts(\n",
    "    df1 = df_clause,\n",
    "    df2 = df_labeled_crossed,\n",
    "    df1_cols = ['sentence_id', 'sentence'],\n",
    "    df2_cols = ['id1', 'id2']\n",
    ")\n",
    "\n",
    "df_labeled_crossed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ab831",
   "metadata": {},
   "source": [
    "## Pre-compute cosine similarities & run FEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute all cosine similarities HERE (Pipeline) so FreeEntailmentAlgorithm\n",
    "# doesn't have to reload the embedding cache or redo this work.\n",
    "# This saves ~88 MB of cache pickling/unpickling and one full pass over 5M+ rows.\n",
    "\n",
    "print(\"Pre-computing cosine similarities in Pipeline...\")\n",
    "\n",
    "# 1. df_candidates → new_cos_sim_score\n",
    "df_candidates = fea.generate_new_bert_results(\n",
    "    df_candidates,\n",
    "    text_col1='text1',\n",
    "    text_col2='text2',\n",
    "    model_path=\"./fine_tuned_bi_model\",\n",
    "    new_col=\"new_cos_sim_score\",\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    id_col1='id1',\n",
    "    id_col2='id2'\n",
    ")\n",
    "print(f\"  ✓ df_candidates: new_cos_sim_score added ({len(df_candidates):,} rows)\")\n",
    "\n",
    "# 2. df_labeled → new_cos_sim_score\n",
    "df_labeled = fea.generate_new_bert_results(\n",
    "    df_labeled,\n",
    "    text_col1='text1',\n",
    "    text_col2='text2',\n",
    "    model_path=\"./fine_tuned_bi_model\",\n",
    "    new_col=\"new_cos_sim_score\",\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    id_col1='id1',\n",
    "    id_col2='id2'\n",
    ")\n",
    "print(f\"  ✓ df_labeled: new_cos_sim_score added ({len(df_labeled)} rows)\")\n",
    "\n",
    "# 3. df_crossed → cosine_sim\n",
    "df_crossed = fea.add_cosine_similarity_from_text(\n",
    "    df_crossed,\n",
    "    text_col1=\"text1\",\n",
    "    text_col2=\"text2\",\n",
    "    model_name=\"./fine_tuned_bi_model\",\n",
    "    batch_size=128,\n",
    "    show_progress_bar=False,\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    id_col1='id1',\n",
    "    id_col2='id2'\n",
    ")\n",
    "print(f\"  ✓ df_crossed: cosine_sim added ({len(df_crossed):,} rows)\")\n",
    "\n",
    "# 4. df_labeled_crossed → cosine_sim\n",
    "df_labeled_crossed = fea.add_cosine_similarity_from_text(\n",
    "    df_labeled_crossed,\n",
    "    text_col1=\"text1\",\n",
    "    text_col2=\"text2\",\n",
    "    model_name=\"./fine_tuned_bi_model\",\n",
    "    batch_size=128,\n",
    "    show_progress_bar=False,\n",
    "    embedding_cache=embedding_cache_finetuned,\n",
    "    id_col1='id1',\n",
    "    id_col2='id2'\n",
    ")\n",
    "print(f\"  ✓ df_labeled_crossed: cosine_sim added ({len(df_labeled_crossed)} rows)\")\n",
    "\n",
    "print(\"✓ All cosine similarities pre-computed in Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a77e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing FreeEntailmentAlgorithm.ipynb for iteration 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13281ef170b4b4a856d2c166e768b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/34 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retrieved outputs:\n",
      "  - df_final: 3748 rows\n",
      "  - fig_html: HTML plot (14714 chars)\n",
      "  - estimated_cost_all_pairs: $7.1918\n"
     ]
    }
   ],
   "source": [
    "import gc, os, pickle\n",
    "\n",
    "temp_dir = \"fea_iterations/temp_data\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "n_cand = len(df_candidates)\n",
    "n_obs  = len(df_obs_ent)\n",
    "\n",
    "if n_cand == 0 or n_obs == 0:\n",
    "    print(f\"⚠ Skipping FreeEntailmentAlgorithm (empty data: \"\n",
    "          f\"{n_cand} candidates, {n_obs} entailed pairs)\")\n",
    "    df_final = pd.DataFrame(\n",
    "        columns=['id1', 'id2', 'text1', 'text2', 'entailment_probability'])\n",
    "    fig_html = \"<p>No data for this iteration</p>\"\n",
    "else:\n",
    "    # 1. Pickle all DataFrames to disk for FreeEntailmentAlgorithm\n",
    "    #    Cosine similarities are already computed — no need to pickle embedding_cache.\n",
    "    df_candidates.to_pickle(f\"{temp_dir}/df_candidates.pkl\")\n",
    "    print(f\"  Pickled df_candidates: {n_cand:,} rows, cols={list(df_candidates.columns)}\")\n",
    "    df_crossed.to_pickle(f\"{temp_dir}/df_crossed.pkl\")\n",
    "    df_labeled.to_pickle(f\"{temp_dir}/df_labeled.pkl\")\n",
    "    df_labeled_crossed.to_pickle(f\"{temp_dir}/df_labeled_crossed.pkl\")\n",
    "    df_obs_ent.to_pickle(f\"{temp_dir}/df_obs_ent.pkl\")\n",
    "    df_clause.to_pickle(f\"{temp_dir}/df_clause.pkl\")\n",
    "\n",
    "    # 2. FREE all large DataFrames BEFORE spawning FreeEntailmentAlgorithm.\n",
    "    #    papermill runs a NEW kernel process — if we keep these in memory,\n",
    "    #    we'd have two copies of the 75M-row DataFrame across two processes.\n",
    "    try: del df_candidates\n",
    "    except NameError: pass\n",
    "    try: del df_predict\n",
    "    except NameError: pass\n",
    "    try: del df_crossed\n",
    "    except NameError: pass\n",
    "    try: del df_labeled_crossed\n",
    "    except NameError: pass\n",
    "    try: del df_obs_ent\n",
    "    except NameError: pass\n",
    "    try: del equiv_map\n",
    "    except NameError: pass\n",
    "    gc.collect()\n",
    "    print(\"  ✓ Freed large DataFrames before FreeEntailmentAlgorithm subprocess\")\n",
    "\n",
    "    # 3. Execute FreeEntailmentAlgorithm (data already on disk)\n",
    "    df_final, fig_html = fea.run_fea_papermill(\n",
    "        iteration_number=iteration_number,\n",
    "        temp_dir=temp_dir,\n",
    "        data_on_disk=True,\n",
    "    )\n",
    "\n",
    "print(f\"✓ df_final: {len(df_final)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7ab8a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>entailment_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0589007p</td>\n",
       "      <td>S0000863004p</td>\n",
       "      <td>The rebellion was provoked by the subjects' at...</td>\n",
       "      <td>King Charles I believed that asserting his aut...</td>\n",
       "      <td>0.637147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1114001sc</td>\n",
       "      <td>S0000941002sc</td>\n",
       "      <td>The connection between protection and obedienc...</td>\n",
       "      <td>to advocate for peace</td>\n",
       "      <td>0.706039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0244004p</td>\n",
       "      <td>S0024289007p</td>\n",
       "      <td>Parliaments possess the power to create and ab...</td>\n",
       "      <td>It is crucial to maintain a clear separation b...</td>\n",
       "      <td>0.708335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B0351002sc</td>\n",
       "      <td>S0003513002sc</td>\n",
       "      <td>The assembly of estates has the authority to p...</td>\n",
       "      <td>The House of Commons must protect the relation...</td>\n",
       "      <td>0.720604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B0403006p</td>\n",
       "      <td>S0020750006p</td>\n",
       "      <td>The power to grant pardons distinguishes the s...</td>\n",
       "      <td>The implications of allowing these pardons ext...</td>\n",
       "      <td>0.260410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id1            id2  \\\n",
       "2    B0589007p   S0000863004p   \n",
       "4   B1114001sc  S0000941002sc   \n",
       "5    B0244004p   S0024289007p   \n",
       "14  B0351002sc  S0003513002sc   \n",
       "18   B0403006p   S0020750006p   \n",
       "\n",
       "                                                text1  \\\n",
       "2   The rebellion was provoked by the subjects' at...   \n",
       "4   The connection between protection and obedienc...   \n",
       "5   Parliaments possess the power to create and ab...   \n",
       "14  The assembly of estates has the authority to p...   \n",
       "18  The power to grant pardons distinguishes the s...   \n",
       "\n",
       "                                                text2  entailment_probability  \n",
       "2   King Charles I believed that asserting his aut...                0.637147  \n",
       "4                               to advocate for peace                0.706039  \n",
       "5   It is crucial to maintain a clear separation b...                0.708335  \n",
       "14  The House of Commons must protect the relation...                0.720604  \n",
       "18  The implications of allowing these pardons ext...                0.260410  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f28aa4",
   "metadata": {},
   "source": [
    "# Task 2: Cleaning LLM Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f6db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5958936666666665"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap at 100k pairs max — send ALL pairs above threshold (no random subsampling)\n",
    "MAX_LLM_PAIRS = 1000\n",
    "\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "if len(df_final) > MAX_LLM_PAIRS:\n",
    "    df_to_llm = df_final.sample(n=MAX_LLM_PAIRS, random_state=42)\n",
    "    print(f\"Capped df_to_llm at {MAX_LLM_PAIRS:,} (from {len(df_final):,} above threshold)\")\n",
    "else:\n",
    "    df_to_llm = df_final.copy()\n",
    "    print(f\"Sending all {len(df_to_llm):,} pairs above threshold to LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7d020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id_2</th>\n",
       "      <th>sentence_id_1</th>\n",
       "      <th>sentence_text_2</th>\n",
       "      <th>argument_id_2</th>\n",
       "      <th>sentence_text_1</th>\n",
       "      <th>argument_id_1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>S0005432003p</td>\n",
       "      <td>B1157006p</td>\n",
       "      <td>Upholding parliamentary authority is essential...</td>\n",
       "      <td>S00054</td>\n",
       "      <td>The governance ensured by the elected leader i...</td>\n",
       "      <td>B1157</td>\n",
       "      <td>0.720720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>S0018405001p</td>\n",
       "      <td>B0273002p</td>\n",
       "      <td>The necessity for immediate and decisive advic...</td>\n",
       "      <td>S00184</td>\n",
       "      <td>The foundation of a king's authority is rooted...</td>\n",
       "      <td>B0273</td>\n",
       "      <td>0.614942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>S0003019001sc</td>\n",
       "      <td>B0223001sc</td>\n",
       "      <td>The proposed Paper Address to the king require...</td>\n",
       "      <td>S00030</td>\n",
       "      <td>Limiting a King's authority to the consent of ...</td>\n",
       "      <td>B0223</td>\n",
       "      <td>0.687784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>S0051611003p</td>\n",
       "      <td>B1140007p</td>\n",
       "      <td>The potential abuse of power by the monarchy n...</td>\n",
       "      <td>S00516</td>\n",
       "      <td>By distancing blood-relations from power, the ...</td>\n",
       "      <td>B1140</td>\n",
       "      <td>0.386518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>S0020972001p</td>\n",
       "      <td>B0778006p</td>\n",
       "      <td>The necessity of immediate action by Parliamen...</td>\n",
       "      <td>S00209</td>\n",
       "      <td>The King must act in accordance with the legal...</td>\n",
       "      <td>B0778</td>\n",
       "      <td>0.666680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id_2 sentence_id_1  \\\n",
       "3039   S0005432003p     B1157006p   \n",
       "152    S0018405001p     B0273002p   \n",
       "681   S0003019001sc    B0223001sc   \n",
       "5947   S0051611003p     B1140007p   \n",
       "6813   S0020972001p     B0778006p   \n",
       "\n",
       "                                        sentence_text_2 argument_id_2  \\\n",
       "3039  Upholding parliamentary authority is essential...        S00054   \n",
       "152   The necessity for immediate and decisive advic...        S00184   \n",
       "681   The proposed Paper Address to the king require...        S00030   \n",
       "5947  The potential abuse of power by the monarchy n...        S00516   \n",
       "6813  The necessity of immediate action by Parliamen...        S00209   \n",
       "\n",
       "                                        sentence_text_1 argument_id_1  \\\n",
       "3039  The governance ensured by the elected leader i...         B1157   \n",
       "152   The foundation of a king's authority is rooted...         B0273   \n",
       "681   Limiting a King's authority to the consent of ...         B0223   \n",
       "5947  By distancing blood-relations from power, the ...         B1140   \n",
       "6813  The King must act in accordance with the legal...         B0778   \n",
       "\n",
       "         score  \n",
       "3039  0.720720  \n",
       "152   0.614942  \n",
       "681   0.687784  \n",
       "5947  0.386518  \n",
       "6813  0.666680  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_llm = fea.format_df_to_llm(df_to_llm, df_clause=df_clause, id_col='sentence_id', text_col='sentence')\n",
    "df_to_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11d6619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1874, 7)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_llm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473fd4b",
   "metadata": {},
   "source": [
    "# Next loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bf720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST MODE: Mocking LLM responses\n",
      "============================================================\n",
      "✓ Matched 1874/1874 pairs with mock LLM results\n",
      "✓ Removed 1874 pairs from remaining LLM calls\n",
      "✓ Remaining pairs for future iterations: 6126\n",
      "✓ Saved 1874 pairs with LLM results to fea_iterations/llm_batch_iter_1.csv\n",
      "\n",
      "Iteration 1 complete\n",
      "Total accumulated cost: $0.0000\n"
     ]
    }
   ],
   "source": [
    "# Reload unlabeled_pairs from pickle if in production mode.\n",
    "# It was freed earlier to save memory while FreeEntailmentAlgorithm ran.\n",
    "if not test and unlabeled_pairs_path:\n",
    "    import gc\n",
    "    unlabeled_pairs = pd.read_pickle(unlabeled_pairs_path)\n",
    "    print(f\"Reloaded unlabeled_pairs: {len(unlabeled_pairs):,} rows\")\n",
    "    gc.collect()\n",
    "\n",
    "result = fea.finalize_pipeline_iteration(\n",
    "    test=test,\n",
    "    df_to_llm=df_to_llm,\n",
    "    iteration_number=iteration_number,\n",
    "    remaining_llm_calls=remaining_llm_calls,\n",
    "    remaining_llm_calls_path=remaining_llm_calls_path,\n",
    "    unlabeled_pairs=unlabeled_pairs,\n",
    "    unlabeled_pairs_path=unlabeled_pairs_path,\n",
    ")\n",
    "\n",
    "remaining_llm_calls = result['remaining_llm_calls']\n",
    "unlabeled_pairs = result['unlabeled_pairs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
